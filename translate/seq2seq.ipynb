{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import nltk\n",
    "import pkuseg\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torch.nn.utils.rnn import pad_packed_sequence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>读取数据</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据并处理成中英文列表，两个列表相同索引位置为对应译文\n",
    "def load_data(filename):\n",
    "    en = []\n",
    "    cn = []\n",
    "    seg = pkuseg.pkuseg()\n",
    "    with open(filename) as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.strip().split('\\t')\n",
    "            en.append(['BOS'] + nltk.word_tokenize(line[0].lower()) + ['EOS'])\n",
    "            cn.append(['BOS'] + [c for c in line[1]] + ['EOS'])\n",
    "    return en, cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和验证集\n",
    "def train_val_split(en, cn, split=0.1):\n",
    "    val_len = int(len(en) * split)\n",
    "    val_index = np.random.choice(len(en), val_len, replace=False)\n",
    "    train_en = []\n",
    "    train_cn = []\n",
    "    val_en = []\n",
    "    val_cn = []\n",
    "    for i in range(len(en)):\n",
    "        if i in val_index:\n",
    "            val_en.append(en[i])\n",
    "            val_cn.append(cn[i])\n",
    "        else:\n",
    "            train_en.append(en[i])\n",
    "            train_cn.append(cn[i])\n",
    "    \n",
    "    return train_en, train_cn, val_en, val_cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自己找的数据集\n",
    "filename = 'datasets/cmn.txt'\n",
    "en, cn = load_data(filename)\n",
    "train_en, train_cn, val_en, val_cn = train_val_split(en, cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_en len: 18120\n",
      "train_cn len: 18120\n",
      "val_en len: 2013\n",
      "val_cn len: 2013\n"
     ]
    }
   ],
   "source": [
    "print('train_en len:', len(train_en))\n",
    "print('train_cn len:', len(train_cn))\n",
    "print('val_en len:', len(val_en))\n",
    "print('val_cn len:', len(val_cn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>构建词表</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_ID = 1\n",
    "PAD_ID = 0\n",
    "\n",
    "def build_vocab(text, max_words=None):\n",
    "    word_count = Counter()\n",
    "    for sentence in text:\n",
    "        word_count.update(sentence)\n",
    "    if not max_words:\n",
    "        max_words = len(word_count)\n",
    "    word_count = word_count.most_common(max_words)\n",
    "    \n",
    "    vocab_size = max_words + 2\n",
    "    word2ix = {item[0] : i+2 for i, item in enumerate(word_count)}\n",
    "    word2ix['UNK'] = UNK_ID\n",
    "    word2ix['PAD'] = PAD_ID\n",
    "    \n",
    "    return word2ix, vocab_size\n",
    "\n",
    "en_word2ix, en_vocab_size = build_vocab(en)\n",
    "cn_word2ix, cn_vocab_size = build_vocab(cn)\n",
    "\n",
    "en_ix2word = {ix:word for word, ix in en_word2ix.items()}\n",
    "cn_ix2word = {ix:word for word, ix in cn_word2ix.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>构建Dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换成数字编码\n",
    "def encode(en, cn):\n",
    "    encode_en = [[en_word2ix[word] for word in sentence] for sentence in en]\n",
    "    encode_cn = [[cn_word2ix[word] for word in sentence] for sentence in cn]\n",
    "    return encode_en, encode_cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数字编码后的数据\n",
    "train_data_en, train_data_cn = encode(en,cn)\n",
    "val_data_en, val_data_cn = encode(en, cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class translateDataset(Dataset):\n",
    "    def __init__(self, en, cn):\n",
    "        self.en = en\n",
    "        self.cn = cn\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        en_sentence = torch.LongTensor(self.en[index])\n",
    "        cn_sentence = torch.LongTensor(self.cn[index])\n",
    "        return en_sentence, cn_sentence\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    en, cn = zip(*data)\n",
    "    en_lengths = [len(sentence) for sentence in en]\n",
    "    cn_lengths = [len(sentence) for sentence in cn]\n",
    "    \n",
    "    en_batch_length = max(en_lengths)\n",
    "    cn_batch_length = max(cn_lengths)\n",
    "    \n",
    "    target_en = torch.zeros(len(en), en_batch_length).long()\n",
    "    target_cn = torch.zeros(len(cn), cn_batch_length).long()\n",
    "    \n",
    "    for i in range(len(en)):\n",
    "        en_text = en[i]\n",
    "        cn_text = cn[i]\n",
    "        \n",
    "        en_len = en_lengths[i]\n",
    "        cn_len = cn_lengths[i]\n",
    "        \n",
    "        target_en[i, :en_len] = en_text\n",
    "        target_cn[i, :cn_len] = cn_text\n",
    "    en_lengths = torch.LongTensor(en_lengths)\n",
    "    cn_lengths = torch.LongTensor(cn_lengths)\n",
    "    return target_en, en_lengths, target_cn, cn_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(batch_size=100, shuffle=True):\n",
    "    train_dataset = translateDataset(train_data_en, train_data_cn)\n",
    "    val_dataset = translateDataset(val_data_en, val_data_cn)\n",
    "    \n",
    "    train_dataloader = DataLoader(dataset=train_dataset\n",
    "                                 ,batch_size=batch_size\n",
    "                                 ,shuffle=shuffle\n",
    "                                 ,pin_memory=True\n",
    "                                 ,collate_fn=collate_fn)\n",
    "    \n",
    "    val_dataloader = DataLoader(dataset=val_dataset\n",
    "                                 ,batch_size=batch_size\n",
    "                                 ,shuffle=shuffle\n",
    "                                 ,pin_memory=True\n",
    "                                 ,collate_fn=collate_fn)\n",
    "    return train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, val_dataloader = get_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建encoder-decoder模型(没有attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>encoder部分</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlainEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=1, dropout=0.2):\n",
    "        super(PlainEncoder, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.gru = nn.GRU(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, lengths):\n",
    "        '''\n",
    "        x: (batch_size , seq_len)\n",
    "        lengths: (batch_size,)\n",
    "        '''\n",
    "        sorted_len, sorted_index = lengths.sort(0, descending=True)\n",
    "        \n",
    "        sorted_x = x[sorted_index.long()]\n",
    "        embed = self.dropout(self.embed(sorted_x))\n",
    "        # embed: (batch_size , seq_len , embed_size)\n",
    "        \n",
    "        packed_embed = pack_padded_sequence(embed, sorted_len, batch_first=True)\n",
    "        \n",
    "        out, hidden = self.gru(packed_embed)\n",
    "        # hidden: h_n = (1 , batch_size , hidden_size)\n",
    "        \n",
    "        out, _ = pad_packed_sequence(out, batch_first=True) # 其实encoder部分可以不用out，只需要hidden就行了，但是加了attention就必须要了\n",
    "        # out: (batch_size , seq_len , hidden_size)\n",
    "        \n",
    "        # 下面的操作就是还原index\n",
    "        _, orginal_index = sorted_index.sort(0)\n",
    "        out = out[orginal_index.long()].contiguous()\n",
    "        hidden = hidden[:,orginal_index.long()].contiguous()\n",
    "        # out: (batch_size , seq_len , embed_size)\n",
    "        # hidden: h_n = (1 , batch_size , hidden_size)\n",
    "        \n",
    "        return out, hidden[[-1]]      # [-1]表示取最后一个元素并保持维度数，\n",
    "                                      # 例如hidden的shape为(3,4,5)，那么hidden[[-1]]的维度为(1,4,5)；而hidden[-1]为(4,5)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>decoder部分</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlainDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=1, dropout=0.2):\n",
    "        super(PlainDecoder, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.gru = nn.GRU(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, y, lengths, hidden):\n",
    "        sorted_len, sorted_index = lengths.sort(0, descending=True)\n",
    "        \n",
    "        sorted_y = y[sorted_index.long()]\n",
    "        hidden = hidden[:, sorted_index.long()]\n",
    "        \n",
    "        embed = self.dropout(self.embed(sorted_y))\n",
    "        \n",
    "        packed_embed = pack_padded_sequence(embed, sorted_len, batch_first=True)\n",
    "        \n",
    "        out, hidden = self.gru(packed_embed, hidden)\n",
    "        # h_n = (1 , batch_size , hidden_size)\n",
    "        out, _ = pad_packed_sequence(out,batch_first=True)\n",
    "        # out: (batch_size , seq_len , embed_size)\n",
    "        \n",
    "        _, orginal_index = sorted_index.sort(0)\n",
    "        \n",
    "        out = out[orginal_index.long()].contiguous()\n",
    "        hidden = hidden[:,orginal_index.long()].contiguous()\n",
    "        \n",
    "        output = self.fc(out)\n",
    "        output = F.log_softmax(output, -1)\n",
    "        # output: (batch_size, seq_len, vocab_size)\n",
    "        \n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Seq2seq模型</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlainSeq2seq(nn.Module):\n",
    "    def __init__(self, en_vocab_size, cn_vocab_size, embed_size, hidden_size, num_layers=1, dropout=0.2):\n",
    "        super(PlainSeq2seq, self).__init__()\n",
    "        self.encoder = PlainEncoder(en_vocab_size, embed_size, hidden_size, num_layers, dropout)\n",
    "        self.decoder = PlainDecoder(cn_vocab_size, embed_size, hidden_size, num_layers, dropout)\n",
    "        \n",
    "    def forward(self, en_data, en_lengths, cn_data, cn_lengths):\n",
    "        _, hidden = self.encoder(en_data, en_lengths)\n",
    "        output, _ = self.decoder(cn_data, cn_lengths, hidden)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def translate(self, en, cn_word2ix, cn_ix2word, max_len=10):\n",
    "        '''\n",
    "        输入：一句经过编码的句子,shape为(seq_len, )\n",
    "        '''\n",
    "        en_lengths = torch.LongTensor([len(en)]).to(en.device)\n",
    "        # en_lengths: (1,) , 即batch_size = 1\n",
    "        en = en.unsqueeze(0)\n",
    "        # en: (1, seq_len) , 即batch_size = 1\n",
    "        _, hidden = self.encoder(en, en_lengths)\n",
    "        # hidden: (1, 1, hidden_size)\n",
    "        y = torch.LongTensor([[cn_word2ix['BOS']]]).to(en.device)\n",
    "        # y:(1, 1)\n",
    "        res = []\n",
    "        for i in range(max_len):\n",
    "            output, hidden = self.decoder(y, torch.ones(1,).long().to(y.device),hidden=hidden)\n",
    "            # output: (1,1,vocab_size), 经过log_softmax后的output\n",
    "            y = output.max(2, keepdim=True)[1].view(-1,1)\n",
    "            index = y.item()\n",
    "            res.append(index)\n",
    "            if index==cn_word2ix['EOS']:\n",
    "                break\n",
    "        preds = [cn_ix2word[word] for word in res]\n",
    "        \n",
    "        return preds\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>定义损失函数</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModelLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LanguageModelLoss, self).__init__()\n",
    "    \n",
    "    def forward(self, outputs, targets, mask):\n",
    "        '''\n",
    "        outputs: (batch_size, max_seq_len, vocab_size)\n",
    "        targets: (batch_size, max_seq_len)\n",
    "        mask: (batch_size, max_seq_len)\n",
    "        '''\n",
    "        outputs = outputs.contiguous().view(-1, outputs.size(2))\n",
    "        # outputs: (batch_size * max_seq_len,  vocab_size)\n",
    "        targets = targets.contiguous().view(-1, 1)\n",
    "        # targets: (batch_size * max_seq_len, 1)\n",
    "        mask = mask.contiguous().view(-1,1)\n",
    "        # mask: (batch_size * max_seq_len, 1)\n",
    "        \n",
    "        losses = -outputs.gather(1, targets) * mask\n",
    "        \n",
    "        loss = torch.sum(losses) / torch.sum(mask)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>训练函数</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data_loader, dev_data_loader, model, optimizer, loss_fn, device, max_epochs=2):\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        for iteration, (en_data, en_lengths, cn_data, cn_lengths) in enumerate(train_data_loader):\n",
    "            en_data = en_data.to(device)\n",
    "            en_lengths = en_lengths.to(device)\n",
    "            cn_input = cn_data[:, :-1].to(device)\n",
    "            cn_target = cn_data[:, 1:].to(device)\n",
    "            cn_lengths = (cn_lengths-1).to(device)\n",
    "            \n",
    "            preds = model(en_data, en_lengths, cn_input, cn_lengths)\n",
    "            \n",
    "            mask = torch.arange(cn_lengths.max().item(), device=device)[None,:] < cn_lengths[:,None]\n",
    "            mask = mask.float()\n",
    "            \n",
    "            loss = loss_fn(preds, cn_target, mask)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # 为了防止梯度过大\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5.)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            if iteration%100 == 0:\n",
    "                print('Epoch: ', epoch, ' |  Iteration', iteration, ' |  loss: ', loss.item())\n",
    "        if epoch % 3 == 0:\n",
    "            dev_loss = evaluate(dev_data_loader, model, loss_fn, device)\n",
    "            if dev_loss < best_loss:\n",
    "                best_model = model\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>验证函数</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dev_data_loader, model, loss_fn, deivce):\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for iteration, (en_data, en_lengths, cn_data, cn_lengths) in enumerate(dev_data_loader):\n",
    "            en_data = en_data.to(device)\n",
    "            en_lengths = en_lengths.to(device)\n",
    "            cn_data = cn_data.to(device)\n",
    "            cn_input = cn_data[:, :-1].to(device)\n",
    "            cn_target = cn_data[:, 1:].to(device)\n",
    "            cn_lengths = (cn_lengths-1).to(device)\n",
    "            \n",
    "            preds = model(en_data, en_lengths, cn_input, cn_lengths)\n",
    "            \n",
    "            mask = torch.arange(cn_lengths.max().item(), device=device)[None,:] < cn_lengths[:,None]\n",
    "            mask = mask.float()\n",
    "            \n",
    "            loss = loss_fn(preds, cn_target, mask)\n",
    "            total_loss += loss.item()\n",
    "    print('Dev Loss: ', total_loss / len(dev_data_loader))\n",
    "    return total_loss / len(dev_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>实例化模型、优化器、损失函数等</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0  |  Iteration 0  |  loss:  8.136415481567383\n",
      "Epoch:  0  |  Iteration 100  |  loss:  5.082197189331055\n",
      "Epoch:  0  |  Iteration 200  |  loss:  4.714270114898682\n",
      "Dev Loss:  4.7327397011294225\n",
      "Epoch:  1  |  Iteration 0  |  loss:  4.807676315307617\n",
      "Epoch:  1  |  Iteration 100  |  loss:  4.427006244659424\n",
      "Epoch:  1  |  Iteration 200  |  loss:  4.273153305053711\n",
      "Epoch:  2  |  Iteration 0  |  loss:  4.245406150817871\n",
      "Epoch:  2  |  Iteration 100  |  loss:  4.034611225128174\n",
      "Epoch:  2  |  Iteration 200  |  loss:  4.041211128234863\n",
      "Epoch:  3  |  Iteration 0  |  loss:  3.9484055042266846\n",
      "Epoch:  3  |  Iteration 100  |  loss:  3.6403651237487793\n",
      "Epoch:  3  |  Iteration 200  |  loss:  3.780123233795166\n",
      "Dev Loss:  3.60898481501211\n",
      "Epoch:  4  |  Iteration 0  |  loss:  3.584219455718994\n",
      "Epoch:  4  |  Iteration 100  |  loss:  3.7775299549102783\n",
      "Epoch:  4  |  Iteration 200  |  loss:  3.6223015785217285\n",
      "Epoch:  5  |  Iteration 0  |  loss:  3.5877466201782227\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-edeb70b457d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLanguageModelLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-87a2ed9ffb5d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_data_loader, dev_data_loader, model, optimizer, loss_fn, device, max_epochs)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PYTHONENV/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    101\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "en_vocab_size = len(en_word2ix)\n",
    "cn_vocab_size = len(cn_word2ix)\n",
    "\n",
    "embed_size = 100\n",
    "hidden_size = 100\n",
    "num_layers = 1\n",
    "dropout = 0.2\n",
    "lr = 0.01\n",
    "\n",
    "model = PlainSeq2seq(en_vocab_size, cn_vocab_size, embed_size, hidden_size, num_layers, dropout).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = LanguageModelLoss().to(device)\n",
    "\n",
    "best_model = train(train_dataloader, val_dataloader, model, optimizer, loss_fn, device, max_epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>实例验证</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_dev(model, val_en, val_cn, i, device):\n",
    "    en_sent = \" \".join([en_ix2word[idx] for idx in val_en[i]])\n",
    "    print(en_sent)\n",
    "    cn_sent = \" \".join([cn_ix2word[idx] for idx in val_cn[i]])\n",
    "    print(cn_sent)\n",
    "    \n",
    "    input_en = torch.LongTensor(val_en[i]).to(device)\n",
    "    trans = model.translate(input_en, cn_word2ix, cn_ix2word, max_len=10)\n",
    "    if trans[-1] == 'EOS':\n",
    "        trans.pop()\n",
    "    print(\" \".join(trans))\n",
    "    print(\"-------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100,125):\n",
    "    translate_dev(best_model, val_data_en, val_data_cn, i, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建encoder-decoder模型(attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**实现注意事项**</font>  \n",
    "1. Luong Attetion模型和Bahdanau Attention模型的不同  \n",
    "2. 注意训练过程rnn的输出并不需要输入进下一个time step中，而是仅仅在预测阶段才输入下一个time step中。这其实就是<font color='red'>**teacher forcing**</font>  \n",
    "3. 在rnn的输出h_n中,h_n[0]表示第一层的前向输出的隐藏状态, h_n[1]表示第一层的后向输出的隐藏状态；h_n[2]表示第二层...前向...,h_n[3]...第二层...后向..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>encoder部分</font>  \n",
    "1. 双向GRU  \n",
    "2. 两层堆叠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, en_hidden_size, de_hidden_size, num_layers=2, dropout=0.2):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        \n",
    "        self.gru = nn.GRU(embed_size, hidden_size, num_layers=num_layers, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(2 * en_hidden_size, de_hidden_size)\n",
    "        \n",
    "    def forward(self, en, en_lengths):\n",
    "        # en : (batch_size, max_seq_len)\n",
    "        # en_lengths : (batch_size, )\n",
    "        sorted_len, sorted_idx = en_lengths.sort(0, descending=True)\n",
    "        \n",
    "        sorted_en = en[sorted_idx.long()]\n",
    "        \n",
    "        embed = self.dropout(self.embed(sorted_en))\n",
    "        # embed : (batch_size, max_seq_len, embed_size)\n",
    "        \n",
    "        packed_embed = pack_padded_sequence(embed, sorted_len, batch_first=True)\n",
    "        \n",
    "        packed_output, hidden = self.gru(packed_embed)\n",
    "        \n",
    "        # hidden : (num_layers * num_directions, batch_size, en_hidden_size)\n",
    "        #          (2, batch_size, en_hidden_size) (由于gru的bidirectional为True，所以这里有个2)\n",
    "        \n",
    "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        \n",
    "        # output: (batch_size, seq_len, 2 * hidden_size) (由于gru的bidirectional为True，所以这里有个2)\n",
    "        # 这个output在attention中需要\n",
    "        _, orginal_idx = sorted_idx.sort(0)\n",
    "        output = output[orginal_idx.long()].contiguous()\n",
    "        \n",
    "        ##############################\n",
    "        # 错误代码： hidden = hidden[orginal_idx.long()].contiguous()\n",
    "        # 这句代码卡了一个晚上加一个白天，居然是维度弄错了。。。真是醉了，用的测试用例因为数量太少居然通过了\n",
    "        \n",
    "        hidden = hidden[:, orginal_idx.long()].contiguous()\n",
    "        \n",
    "        \n",
    "        ###############################\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 由于在Luong Attention模型中decoder为单向的RNN，所以encoder输出的hidden要作一些变换\n",
    "        hidden = torch.cat((hidden[0::2], hidden[1::2]), dim=2)\n",
    "        # hidden: (num_layers, batch_size, en_hidden_size * 2)\n",
    "        hidden = self.fc(hidden)\n",
    "        # hidden: (num_layers, batch_size, de_hidden_size)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Attention部分</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**实现注意事项**</font>  \n",
    "1. 计算context的时候，需要将encoder的output的隐状态转换为与decoder隐状态相同的维度(这是fc_in为（en_hidden_size * 2, de_hidden_size）的原因)，但是在计算attention后的向量的时候用的还是原来的encoder的output(这是为什么fc\\_out为（en_hidden_size * 2 + de_hidden_size, de_hidden_size）的原因)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, en_hidden_size, de_hidden_size):\n",
    "        # 由于encoder是bidirectional，所以先要处理encoder的output\n",
    "        super(Attention, self).__init__()\n",
    "        self.fc_in = nn.Linear(en_hidden_size * 2, de_hidden_size)\n",
    "        self.fc_out = nn.Linear(en_hidden_size * 2 + de_hidden_size, de_hidden_size)\n",
    "    \n",
    "    def forward(self, ht, en_output, mask):\n",
    "        # ht: (batch_size, de_seq_len, de_hidden_size)\n",
    "        # en_output: (batch_size, en_seq_len, 2 * en_hidden_size)\n",
    "        \n",
    "        hs = self.fc_in(en_output)\n",
    "        # hs: (batch_size, en_seq_len, de_hidden_size)\n",
    "        \n",
    "        score = ht.bmm(hs.transpose(1,2))\n",
    "        # socre:(batch_size, de_seq_len, en_seq_len)\n",
    "        # score[i,j] 表示decoder的第i个单词隐藏状态的输出和encoder第j个单词隐藏状态输出的得分\n",
    "        \n",
    "        score.data.masked_fill(mask, 1e-6) # 主要是为了防止0经过softmax后占掉一部分比例，使其它有效的区域占的比例下降\n",
    "        \n",
    "        attn = F.softmax(score, dim=2)\n",
    "        # attn:(batch_size, de_seq_len, en_seq_len)\n",
    "        \n",
    "        context = torch.bmm(attn, en_output)\n",
    "        # context: (batch_size, de_seq_len, 2*en_hidden_size)\n",
    "        ht_hat = self.fc_out(torch.cat((context, ht), dim=2))\n",
    "        ht_hat = torch.tanh(ht_hat)\n",
    "        # ht_hat: (batch_size, de_seq_len, de_hidden_size)\n",
    "        \n",
    "        return ht_hat, attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Decoder部分</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 单向GRU(与encoder不同)  \n",
    "2. 两层堆叠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoungAttnDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, en_hidden_size, de_hidden_size, num_layers=2, dropout=0.2):\n",
    "        super(LoungAttnDecoder, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.gru = nn.GRU(embed_size, de_hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.attention = Attention(en_hidden_size, de_hidden_size)\n",
    "        self.fc = nn.Linear(de_hidden_size, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    \n",
    "    def create_mask(self, en_lengths, cn_lengths, device):\n",
    "        en_max_len = en_lengths.max()\n",
    "        cn_max_len = cn_lengths.max()\n",
    "        \n",
    "        mask_en = torch.arange(en_max_len, device=device)[None,:] < en_lengths[:, None]\n",
    "        # mask_en: (batch_size, en_seq_len)\n",
    "        mask_cn = torch.arange(cn_max_len, device=device)[None,:] < cn_lengths[:, None]\n",
    "        # mask_cn: (batch_size, cn_seq_len)\n",
    "        mask = (mask_en[:,None,:] * mask_cn[:,:,None]).logical_not()\n",
    "        # mask : (batch_size, cn_seq_len, en_seq_len)\n",
    "        \n",
    "        return mask\n",
    "        \n",
    "    def forward(self, en_output,en_lengths, cn, cn_lengths, hidden):\n",
    "        sorted_len, sorted_idx = cn_lengths.sort(0, descending=True)\n",
    "        \n",
    "        sorted_cn = cn[sorted_idx.long()]\n",
    "        hidden = hidden[:, sorted_idx.long()]\n",
    "        \n",
    "        embed = self.dropout(self.embed(sorted_cn))\n",
    "        packed_embed = pack_padded_sequence(embed, sorted_len, batch_first=True)\n",
    "        \n",
    "        packed_out, hidden = self.gru(packed_embed, hidden)\n",
    "        # hidden: (num_layers * num_directions, batch_size, de_hidden_size)    这个hidden似乎没用到\n",
    "        #         (2, batch_size, de_hidden_size) \n",
    "        \n",
    "        output, _ = pad_packed_sequence(packed_out, batch_first=True)\n",
    "        # output : (batch_size, max_seq_len, de_hidden_size)\n",
    "        _, original_idx = sorted_idx.sort(0)\n",
    "        \n",
    "        output = output[original_idx.long()].contiguous()\n",
    "        hidden = hidden[:, original_idx.long()].contiguous()\n",
    "        # output : (batch_size, max_seq_len, de_hidden_size)\n",
    "        # hidden: (num_layers * num_directions, batch_size, de_hidden_size)\n",
    "        \n",
    "        # 由于padding的存在，不是所有的句子的max_seq_len长度都要用到，所以此时需要用一个mask来屏蔽padding的影响。\n",
    "        mask = self.create_mask(en_lengths, cn_lengths, cn.device)\n",
    "        \n",
    "        ht_hat, attn = self.attention(output, en_output, mask)\n",
    "        # ht_hat: (batch_size, de_seq_len, de_hidden_size)\n",
    "        # attn:(batch_size, de_seq_len, en_seq_len)\n",
    "        \n",
    "        output = F.log_softmax(self.fc(ht_hat), -1)\n",
    "        \n",
    "        return output, hidden, attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Seq2seq部分</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2seq(nn.Module):\n",
    "    def __init__(self, en_vocab_size, cn_vocab_size, embed_size, en_hidden_size,de_hidden_size, num_layers=2, dropout=0.2):\n",
    "        super(Seq2seq, self).__init__()\n",
    "        self.encoder = Encoder(en_vocab_size, embed_size, en_hidden_size, de_hidden_size, num_layers, dropout)\n",
    "        self.decoder = LoungAttnDecoder(cn_vocab_size, embed_size, en_hidden_size, de_hidden_size, num_layers, dropout)\n",
    "        \n",
    "    def forward(self, en_data, en_lengths, cn_data, cn_lengths):\n",
    "        en_output, hidden = self.encoder(en_data, en_lengths)\n",
    "        output, _, attn = self.decoder(en_output, en_lengths, cn_data, cn_lengths, hidden)\n",
    "        \n",
    "        return output, attn\n",
    "    \n",
    "    def translate(self, en, cn_word2ix, cn_ix2word, max_len=100):\n",
    "        '''\n",
    "        输入：一句经过编码的句子,shape为(seq_len, )\n",
    "        '''\n",
    "        en_lengths = torch.LongTensor([len(en)]).to(en.device)\n",
    "        # en_lengths: (1,) , 即batch_size = 1\n",
    "        en = en.unsqueeze(0)\n",
    "        # en: (1, seq_len) , 即batch_size = 1\n",
    "        en_output, hidden = self.encoder(en, en_lengths)\n",
    "        # hidden: (1, 1, hidden_size)\n",
    "        y = torch.LongTensor([[cn_word2ix['BOS']]]).to(en.device)\n",
    "        # y:(1, 1)\n",
    "        res = []\n",
    "        for i in range(max_len):\n",
    "            output, hidden, _ = self.decoder(en_output, en_lengths, y, torch.ones(1,).long().to(y.device),hidden=hidden)\n",
    "            # output: (1,1,vocab_size), 经过log_softmax后的output\n",
    "            y = output.max(2, keepdim=True)[1].view(-1,1)\n",
    "            index = y.item()\n",
    "            res.append(index)\n",
    "            if index==cn_word2ix['EOS']:\n",
    "                break\n",
    "        preds = [cn_ix2word[word] for word in res]\n",
    "        \n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>训练函数</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data_loader, dev_data_loader, model, optimizer, loss_fn, device, max_epochs=2):\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        for iteration, (en_data, en_lengths, cn_data, cn_lengths) in enumerate(train_data_loader):\n",
    "            en_data = en_data.to(device)\n",
    "            en_lengths = en_lengths.to(device)\n",
    "            cn_input = cn_data[:, :-1].to(device)\n",
    "            cn_target = cn_data[:, 1:].to(device)\n",
    "            cn_lengths = (cn_lengths-1).to(device)\n",
    "            \n",
    "            preds, attn = model(en_data, en_lengths, cn_input, cn_lengths)\n",
    "            \n",
    "            mask = torch.arange(cn_lengths.max().item(), device=device)[None,:] < cn_lengths[:,None]\n",
    "            mask = mask.float()\n",
    "            \n",
    "            loss = loss_fn(preds, cn_target, mask)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # 为了防止梯度过大\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5.)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            if iteration%100 == 0:\n",
    "                print('Epoch: ', epoch, ' |  Iteration', iteration, ' |  loss: ', loss.item())\n",
    "        if epoch % 3 == 0:\n",
    "            dev_loss = evaluate(dev_data_loader, model, loss_fn, device)\n",
    "            if dev_loss < best_loss:\n",
    "                best_model = model\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>验证函数</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dev_data_loader, model, loss_fn, deivce):\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for iteration, (en_data, en_lengths, cn_data, cn_lengths) in enumerate(dev_data_loader):\n",
    "            en_data = en_data.to(device)\n",
    "            en_lengths = en_lengths.to(device)\n",
    "            cn_data = cn_data.to(device)\n",
    "            cn_input = cn_data[:, :-1].to(device)\n",
    "            cn_target = cn_data[:, 1:].to(device)\n",
    "            cn_lengths = (cn_lengths-1).to(device)\n",
    "            \n",
    "            preds, attn = model(en_data, en_lengths, cn_input, cn_lengths)\n",
    "            \n",
    "            mask = torch.arange(cn_lengths.max().item(), device=device)[None,:] < cn_lengths[:,None]\n",
    "            mask = mask.float()\n",
    "            \n",
    "            loss = loss_fn(preds, cn_target, mask)\n",
    "            total_loss += loss.item()\n",
    "    print('Dev Loss: ', total_loss / len(dev_data_loader))\n",
    "    return total_loss / len(dev_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModelLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LanguageModelLoss, self).__init__()\n",
    "    \n",
    "    def forward(self, outputs, targets, mask):\n",
    "        '''\n",
    "        outputs: (batch_size, max_seq_len, vocab_size)\n",
    "        targets: (batch_size, max_seq_len)\n",
    "        mask: (batch_size, max_seq_len)\n",
    "        '''\n",
    "        outputs = outputs.contiguous().view(-1, outputs.size(2))\n",
    "        # outputs: (batch_size * max_seq_len,  vocab_size)\n",
    "        targets = targets.contiguous().view(-1, 1)\n",
    "        # targets: (batch_size * max_seq_len, 1)\n",
    "        mask = mask.contiguous().view(-1,1)\n",
    "        # mask: (batch_size * max_seq_len, 1)\n",
    "        \n",
    "        losses = -outputs.gather(1, targets) * mask\n",
    "        \n",
    "        loss = torch.sum(losses) / torch.sum(mask)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>实例化模型、优化器、损失函数等</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0  |  Iteration 0  |  loss:  8.145094871520996\n",
      "Epoch:  0  |  Iteration 100  |  loss:  5.452698707580566\n",
      "Epoch:  0  |  Iteration 200  |  loss:  5.094507694244385\n",
      "Dev Loss:  5.169408607010794\n",
      "Epoch:  1  |  Iteration 0  |  loss:  5.136753082275391\n",
      "Epoch:  1  |  Iteration 100  |  loss:  5.139439105987549\n",
      "Epoch:  1  |  Iteration 200  |  loss:  5.13421106338501\n",
      "Epoch:  2  |  Iteration 0  |  loss:  4.9201860427856445\n",
      "Epoch:  2  |  Iteration 100  |  loss:  4.95025634765625\n",
      "Epoch:  2  |  Iteration 200  |  loss:  4.662297248840332\n",
      "Epoch:  3  |  Iteration 0  |  loss:  4.789303302764893\n",
      "Epoch:  3  |  Iteration 100  |  loss:  4.53074836730957\n",
      "Epoch:  3  |  Iteration 200  |  loss:  4.210686206817627\n",
      "Dev Loss:  4.279132002651101\n",
      "Epoch:  4  |  Iteration 0  |  loss:  4.509956359863281\n",
      "Epoch:  4  |  Iteration 100  |  loss:  4.312596321105957\n",
      "Epoch:  4  |  Iteration 200  |  loss:  3.9538726806640625\n",
      "Epoch:  5  |  Iteration 0  |  loss:  4.053697109222412\n",
      "Epoch:  5  |  Iteration 100  |  loss:  3.913032293319702\n",
      "Epoch:  5  |  Iteration 200  |  loss:  3.7106521129608154\n",
      "Epoch:  6  |  Iteration 0  |  loss:  3.7461166381835938\n",
      "Epoch:  6  |  Iteration 100  |  loss:  3.652650833129883\n",
      "Epoch:  6  |  Iteration 200  |  loss:  3.5212597846984863\n",
      "Dev Loss:  3.4707274448753584\n",
      "Epoch:  7  |  Iteration 0  |  loss:  3.8055264949798584\n",
      "Epoch:  7  |  Iteration 100  |  loss:  3.5185770988464355\n",
      "Epoch:  7  |  Iteration 200  |  loss:  3.2342658042907715\n",
      "Epoch:  8  |  Iteration 0  |  loss:  3.344676971435547\n",
      "Epoch:  8  |  Iteration 100  |  loss:  3.1018736362457275\n",
      "Epoch:  8  |  Iteration 200  |  loss:  3.200634002685547\n",
      "Epoch:  9  |  Iteration 0  |  loss:  3.1021111011505127\n",
      "Epoch:  9  |  Iteration 100  |  loss:  3.006342649459839\n",
      "Epoch:  9  |  Iteration 200  |  loss:  3.2050416469573975\n",
      "Dev Loss:  2.871858248616209\n",
      "Epoch:  10  |  Iteration 0  |  loss:  3.072842597961426\n",
      "Epoch:  10  |  Iteration 100  |  loss:  2.8836781978607178\n",
      "Epoch:  10  |  Iteration 200  |  loss:  3.1229286193847656\n",
      "Epoch:  11  |  Iteration 0  |  loss:  2.9049253463745117\n",
      "Epoch:  11  |  Iteration 100  |  loss:  2.4410829544067383\n",
      "Epoch:  11  |  Iteration 200  |  loss:  2.827054262161255\n",
      "Epoch:  12  |  Iteration 0  |  loss:  2.8176262378692627\n",
      "Epoch:  12  |  Iteration 100  |  loss:  2.792686939239502\n",
      "Epoch:  12  |  Iteration 200  |  loss:  2.7132301330566406\n",
      "Dev Loss:  2.3999845828160202\n",
      "Epoch:  13  |  Iteration 0  |  loss:  2.462338447570801\n",
      "Epoch:  13  |  Iteration 100  |  loss:  2.619657516479492\n",
      "Epoch:  13  |  Iteration 200  |  loss:  2.5433170795440674\n",
      "Epoch:  14  |  Iteration 0  |  loss:  2.7089004516601562\n",
      "Epoch:  14  |  Iteration 100  |  loss:  2.46319842338562\n",
      "Epoch:  14  |  Iteration 200  |  loss:  2.3447721004486084\n",
      "Epoch:  15  |  Iteration 0  |  loss:  2.2549514770507812\n",
      "Epoch:  15  |  Iteration 100  |  loss:  2.2474002838134766\n",
      "Epoch:  15  |  Iteration 200  |  loss:  2.3332788944244385\n",
      "Dev Loss:  2.059576359715792\n",
      "Epoch:  16  |  Iteration 0  |  loss:  2.166257858276367\n",
      "Epoch:  16  |  Iteration 100  |  loss:  2.3258347511291504\n",
      "Epoch:  16  |  Iteration 200  |  loss:  2.260425567626953\n",
      "Epoch:  17  |  Iteration 0  |  loss:  2.2322065830230713\n",
      "Epoch:  17  |  Iteration 100  |  loss:  2.1622443199157715\n",
      "Epoch:  17  |  Iteration 200  |  loss:  2.041713237762451\n",
      "Epoch:  18  |  Iteration 0  |  loss:  2.230469226837158\n",
      "Epoch:  18  |  Iteration 100  |  loss:  2.0616421699523926\n",
      "Epoch:  18  |  Iteration 200  |  loss:  2.0488288402557373\n",
      "Dev Loss:  1.8003337017380365\n",
      "Epoch:  19  |  Iteration 0  |  loss:  1.9406417608261108\n",
      "Epoch:  19  |  Iteration 100  |  loss:  2.1229217052459717\n",
      "Epoch:  19  |  Iteration 200  |  loss:  1.998640775680542\n",
      "Epoch:  20  |  Iteration 0  |  loss:  1.9563287496566772\n",
      "Epoch:  20  |  Iteration 100  |  loss:  2.1364290714263916\n",
      "Epoch:  20  |  Iteration 200  |  loss:  2.016296625137329\n",
      "Epoch:  21  |  Iteration 0  |  loss:  1.8190438747406006\n",
      "Epoch:  21  |  Iteration 100  |  loss:  1.9927048683166504\n",
      "Epoch:  21  |  Iteration 200  |  loss:  1.9574346542358398\n",
      "Dev Loss:  1.580065132367729\n",
      "Epoch:  22  |  Iteration 0  |  loss:  1.919843316078186\n",
      "Epoch:  22  |  Iteration 100  |  loss:  1.8975969552993774\n",
      "Epoch:  22  |  Iteration 200  |  loss:  1.8533282279968262\n",
      "Epoch:  23  |  Iteration 0  |  loss:  1.754524827003479\n",
      "Epoch:  23  |  Iteration 100  |  loss:  1.6604417562484741\n",
      "Epoch:  23  |  Iteration 200  |  loss:  1.8006376028060913\n",
      "Epoch:  24  |  Iteration 0  |  loss:  1.736764907836914\n",
      "Epoch:  24  |  Iteration 100  |  loss:  1.786461353302002\n",
      "Epoch:  24  |  Iteration 200  |  loss:  1.7056941986083984\n",
      "Dev Loss:  1.3962363376475797\n",
      "Epoch:  25  |  Iteration 0  |  loss:  1.5381301641464233\n",
      "Epoch:  25  |  Iteration 100  |  loss:  1.713722586631775\n",
      "Epoch:  25  |  Iteration 200  |  loss:  1.7933073043823242\n",
      "Epoch:  26  |  Iteration 0  |  loss:  1.6053502559661865\n",
      "Epoch:  26  |  Iteration 100  |  loss:  1.602446436882019\n",
      "Epoch:  26  |  Iteration 200  |  loss:  1.4649864435195923\n",
      "Epoch:  27  |  Iteration 0  |  loss:  1.6255041360855103\n",
      "Epoch:  27  |  Iteration 100  |  loss:  1.6639220714569092\n",
      "Epoch:  27  |  Iteration 200  |  loss:  1.6894866228103638\n",
      "Dev Loss:  1.2553563253714306\n",
      "Epoch:  28  |  Iteration 0  |  loss:  1.5351451635360718\n",
      "Epoch:  28  |  Iteration 100  |  loss:  1.6485061645507812\n",
      "Epoch:  28  |  Iteration 200  |  loss:  1.5497959852218628\n",
      "Epoch:  29  |  Iteration 0  |  loss:  1.3950233459472656\n",
      "Epoch:  29  |  Iteration 100  |  loss:  1.6665148735046387\n",
      "Epoch:  29  |  Iteration 200  |  loss:  1.4187678098678589\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "en_vocab_size = len(en_word2ix)\n",
    "cn_vocab_size = len(cn_word2ix)\n",
    "\n",
    "embed_size = 100\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "dropout = 0.2\n",
    "lr = 0.01\n",
    "\n",
    "model = Seq2seq(en_vocab_size, cn_vocab_size, embed_size, hidden_size, hidden_size, num_layers, dropout).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = LanguageModelLoss().to(device)\n",
    "\n",
    "best_model = train(train_dataloader, val_dataloader, model, optimizer, loss_fn, device, max_epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>实例验证</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_dev(model, val_en, val_cn, i, device):\n",
    "    en_sent = \" \".join([en_ix2word[idx] for idx in val_en[i]])\n",
    "    print(en_sent)\n",
    "    cn_sent = \" \".join([cn_ix2word[idx] for idx in val_cn[i]])\n",
    "    print(cn_sent)\n",
    "    \n",
    "    input_en = torch.LongTensor(val_en[i]).to(device)\n",
    "    trans = model.translate(input_en, cn_word2ix, cn_ix2word, max_len=10)\n",
    "    if trans[-1] == 'EOS':\n",
    "        trans.pop()\n",
    "    print(\" \".join(trans))\n",
    "    print(\"-------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>效果明显比不带attention的好多了</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOS try some . EOS\n",
      "BOS 试 试 吧 。 EOS\n",
      "试 试 了 。\n",
      "-------------------\n",
      "BOS who died ? EOS\n",
      "BOS 谁 死 了 ？ EOS\n",
      "谁 死 了 誰 ？\n",
      "-------------------\n",
      "BOS birds fly . EOS\n",
      "BOS 鳥 類 飛 行 。 EOS\n",
      "鳥 是 鳥 票 的 。\n",
      "-------------------\n",
      "BOS call home ! EOS\n",
      "BOS 打 电 话 回 家 ！ EOS\n",
      "打 电 话 回 家 ！\n",
      "-------------------\n",
      "BOS catch him . EOS\n",
      "BOS 抓 住 他 。 EOS\n",
      "抓 到 他 。\n",
      "-------------------\n",
      "BOS come home . EOS\n",
      "BOS 回 家 吧 。 EOS\n",
      "来 开 始 家 。\n",
      "-------------------\n",
      "BOS do it now . EOS\n",
      "BOS 現 在 就 做 。 EOS\n",
      "現 在 做 它 。\n",
      "-------------------\n",
      "BOS dogs bark . EOS\n",
      "BOS 狗 会 叫 。 EOS\n",
      "狗 是 不 要 的 。\n",
      "-------------------\n",
      "BOS do n't cry . EOS\n",
      "BOS 别 哭 。 EOS\n",
      "别 哭 了 。\n",
      "-------------------\n",
      "BOS excuse me . EOS\n",
      "BOS 对 不 起 。 EOS\n",
      "对 我 来 。\n",
      "-------------------\n",
      "BOS feel this . EOS\n",
      "BOS 来 感 受 一 下 这 个 。 EOS\n",
      "那 个 。\n",
      "-------------------\n",
      "BOS follow me . EOS\n",
      "BOS 请 跟 我 来 。 EOS\n",
      "跟 我 。\n",
      "-------------------\n",
      "BOS follow us . EOS\n",
      "BOS 请 跟 着 我 们 。 EOS\n",
      "跟 我 们 来 说 。\n",
      "-------------------\n",
      "BOS good luck . EOS\n",
      "BOS 祝 你 好 运 。 EOS\n",
      "祝 你 。\n",
      "-------------------\n",
      "BOS grab that . EOS\n",
      "BOS 抓 住 那 个 。 EOS\n",
      "抓 住 那 个 。\n",
      "-------------------\n",
      "BOS grab this . EOS\n",
      "BOS 抓 住 这 个 。 EOS\n",
      "抓 住 这 个 。\n",
      "-------------------\n",
      "BOS hands off . EOS\n",
      "BOS 手 举 起 来 。 EOS\n",
      "下 来 。\n",
      "-------------------\n",
      "BOS he 's a dj . EOS\n",
      "BOS 他 是 一 个   D J   。 EOS\n",
      "他 是 個 好 梦 。\n",
      "-------------------\n",
      "BOS he 's lazy . EOS\n",
      "BOS 他 很 懒 。 EOS\n",
      "他 是 1 0 萬 大 。\n",
      "-------------------\n",
      "BOS hold fire . EOS\n",
      "BOS 停 火 。 EOS\n",
      "停 火 。\n",
      "-------------------\n",
      "BOS hold this . EOS\n",
      "BOS 我 住 这 个 。 EOS\n",
      "这 是 这 个 。\n",
      "-------------------\n",
      "BOS how awful ! EOS\n",
      "BOS 太 可 怕 了 。 EOS\n",
      "多 少 了 !\n",
      "-------------------\n",
      "BOS i am cold . EOS\n",
      "BOS 我 冷 。 EOS\n",
      "我 冷 。\n",
      "-------------------\n",
      "BOS i am okay . EOS\n",
      "BOS 我 沒 事 。 EOS\n",
      "我 是 谁 。\n",
      "-------------------\n",
      "BOS i am sick . EOS\n",
      "BOS 我 生 病 了 。 EOS\n",
      "我 生 病 了 。\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(100,125):\n",
    "    translate_dev(best_model, val_data_en, val_data_cn, i, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
